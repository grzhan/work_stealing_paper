title: 【译】Scheduling Multithreaded Computations by Work Stealing
date: 2024-05-17 14:26:03
tags:
	- Golang
	- 多线程
	- 并行计算
	- 调度器
	- 论文翻译
categories: 操作系统
---

{% asset_img "banner.png" %}

<!-- toc -->

# 译序

最近在看 [Scalable Go Scheduler Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit)，也就是 Google 的 Dmitry Vyukov 大佬在这篇文档里提出了现在 Golang 调度器使用的 G-M-P 设计，并为调度器引入 Work Stealing 机制以提高资源利用与计算效率（[It does so efficiently in terms of execution time, memory usage, and inter-processor communication](https://en.wikipedia.org/wiki/Work_stealing)）。

事实上不光是 Golang，我发现这也是大部分主流语言的多线程调度器会实现的机制之一（[.Net](https://dl.acm.org/doi/10.1145/1639949.1640106), [Java](https://gee.cs.oswego.edu/dl/papers/fj.pdf), [Rust（tokio）](https://tokio.rs/tokio/tutorial)）。所以作为重要起源的这篇由 Robert D. Blumofe 与 Charles E. Leiserson 在 1999 年发表的论文 [Scheduling Multithreaded Computations by Work Stealing](https://dl.acm.org/doi/abs/10.1109/SFCS.1994.365680) 就很有学习的必要了。

由于我搜了下发现目前中文互联网暂时还没有这篇论文的翻译、解读以及讨论。事实上这是篇个人认为很有价值的一篇论文，**通过学习它掌握一个现代调度器的重要算法对于自己还是对于国内其他开发者而言都是很有价值的**，所以打算投入一定的时间完成这篇论文的翻译工作，并后续写一篇基于这篇论文对于 Work Stealing 算法的解读。阅读这篇论文的过程中也发现以自己目前的功力要完成这篇论文的翻译确实是有点吃力的，所以后面的翻译难免会有不少纰漏以及错误，有发现的老师请及时联系我，我及时勘误。

整篇论文我会通过查询资料以及结合个人理解将其翻译通顺，一些我个人觉得可能我们大部分开发者会觉得陌生的术语我会附上英文原文并加粗，同时我也会附上一些个人觉得有助于理解的译注。

下面开始吧 :)

+ Title:Scheduling Multithreaded Computations by Work Stealing
+ Author: Robert D. Blumofe,  Charles E. Leiserson
+ URL: http://supertech.csail.mit.edu/papers/steal.pdf
+ Journal of the ACM, Vol. 46, No.5, Spectember 1999, pp. 720-748

# 摘要（Abstract）

本文研究了在并行计算机上**高效调度（efficiently scheduling）**、**完全严格（fully strict，即结构良好， well-structured）**的多线程计算的问题。一种流行且实用的调度这种动态 [MIMD 类型](https://en.wikipedia.org/wiki/Multiple_instruction,_multiple_data) 计算的方法是**“工作窃取（work-sealing）”**，在这种方法中，需要工作的处理器从其他处理器窃取计算线程。本文提出了首个针对**具有依赖关系的（with dependencies）**多线程计算的工作窃取调度算法，并可证明其性能良好。


具体来说，我们的分析表明，使用我们的工作窃取调度器在 P 个处理器上执行**完全严格计算（fully strict computation）**的预期时间是 \\(T_1/P + O(T_\infty)\\)，其中 \\(T_1\\) 是多线程计算的**最短串行执行时间**（*译注：即只有一个处理器时串行执行所有任务所需的时间*），\\(T_\infty\\) 是在**无限数量处理器下的最短执行时间**。此外，执行所需的空间最多为 \\(S_1P\\)，其中 \\(S_1\\) 是**最小串行空间需求**（*译注：即只有一个处理器时串行执行所有任务所需的空间*）。

我们还表明，该算法的预期<strong>总通信量 (total communication) </strong> 最多为 \\(O(PT_\infty(1+n_d)S_\text{max})\\)，其中 \\(S_\text{max}\\) 是任意线程的最大**激活记录（activation record，即 [stack frame](https://en.wikipedia.org/wiki/Call_stack#STACK-FRAME)）**大小，\\(n_d\\) 是任何线程与其父线程同步的最大次数。这条通信界限证明了工作窃取调度器在通信效率上优于**工作共享（work-sharing）**调度器的**普遍看法（folk wisdom）**是有道理的。

上述三个界限在**常数因子内都是存在性最优的（existentially optimal to within a constant factor）**。

> *译注：这三个界限在常数因子的范围内是最优的。具体来说，<strong>"存在性最优"（existentially optimal）</strong>表示这些界限在理论上是可以达到的最优水平，虽然可能不是唯一的最优解，但在常数因子内（即乘以一个常数）它们是最优的。这意味着任何实际应用中，性能都不会显著超过这些界限。*


# 1. 引言（Introduction）

为了在 [MIMD 类型](https://en.wikipedia.org/wiki/Multiple_instruction,_multiple_data)的并行计算机上高效执行动态增长的多线程计算，调度算法必须**确保有足够的线程同时处于活跃状态，以保持处理器忙碌**。同时，它还应**确保并发活跃线程的数量保持在合理范围内，以避免内存需求过大**。此外，调度器还**应尽量将相关线程保留在同一处理器上，以最小化它们之间的通信**。不言而喻，同时实现所有这些目标可能会非常困难。

为了解决多线程计算的调度问题，出现了两种调度范式：**工作共享（work sharing）**和**工作窃取（work stealing）**。在工作共享中，每当处理器生成新线程时，调度器会尝试将其中一些线程迁移到其他处理器，希望将工作分配给利用率较低的处理器。然而，在工作窃取中，**利用率较低的处理器会主动尝试从其他处理器“窃取”线程。**直观地说，与工作共享相比，工作窃取的线程迁移发生频率较低，因为**当所有处理器都有工作时，工作窃取调度器不会迁移线程，而工作共享调度器总是会迁移线程**。

工作窃取的理念至少可以追溯到 Burton 和 Sleep 关于函数式程序并行执行的研究 [16] 以及 Halstead 对 Multilisp 的实现[30]。这些作者指出，工作窃取在空间和通信方面具有启发性的好处。自那以后，许多研究人员实现了这种策略的变体[11,21,23,29,34,37,46]。Rudolph、Slivkin-Allalouf 和 Upfal [43] 分析了一种用于在并行计算机上负载平衡独立作业的随机工作窃取策略，Karp 和 Zhang [33] 分析了一种用于并行回溯搜索的随机工作窃取策略。最近，Zhang 和 Ortynski [48] 对该算法的通信需求得到了良好的界限。

在本文中，我们提出并分析了一种用于调度**完全严格（full-strict, 即结构良好 well-structured）**多线程计算的工作窃取算法。这一类计算包括**回溯搜索计算**和**数据流计算** [33,48] 以及**分治计算** [47]，其中线程可能由于数据依赖而暂停。我们在一个**严格的原子访问模型**中分析我们的算法，这个模型类似于 [36] 的原子消息传递模型，其中对同一数据结构的并发访问由**对手（adversary）**串行排队。


我们的主要贡献是一种**随机化的、完全严格的、用于多线程计算的工作窃取调度算法**，该算法在时间、空间和通信方面具有可证明的高效性。我们证明我们的工作窃取调度器在 P 个处理器上执行完全严格计算的预期时间是 \\(T_1/P + O(T_\infty)\\)，其中 \\(T_1\\) 是多线程计算的最短串行执行时间，\\(T_\infty\\) 是在无限数量处理器下的最短执行时间。此外，执行所需的空间最多为 \\(S_1P\\)，其中 \\(S_1\\) 是最小串行空间需求。这些界限优于以前对工作共享调度器的界限 [10]，而且工作窃取调度器更加简单且极其实用。这种改进部分归因于我们专注于**完全严格计算（fully strict computation）**，而不是 [10] 中研究的**一般严格计算（(general) strict computation）**。我们还证明了该算法的预期总通信量 (total communication) 最多为 \\(O(PT_\infty(1+n_d)S_\text{max})\\)，其中 \\(S_\text{max}\\) 是任意线程的最大激活记录大小，\\(n_d\\) 是任何线程与其父线程同步的最大次数。该界限在常数因子范围内是**存在性紧（existentially tight）**的，符合 Wu 和 Kung [47] 对并行分治中通信的下界。相比之下，工作共享调度器在通信方面表现接近最坏情况。因此，我们的结果支持了工作窃取优于工作共享的普遍看法。

> *译注： 这段提到了**完全严格计算**、<strong>(一般)严格计算</strong>， 与 <strong>存在性紧</strong>。 完全严格计算与严格计算的定义后文会说明，这里简单说下存在性紧的理解：*
> +  *<strong>常数因子范围内存在性紧</strong>：指在常数因子范围内达到最优，意思是所得到的上界（算法的性能或资源消耗）在某个常数倍内接近理论上的最优下界。换句话说，这个界限几乎达到了理论上可能的最优状态，仅仅差一个常数因子。*

也有很多其他学者已经研究并正在继续研究如何高效管理并行计算的空间需求。Culler 和 Arvind [19] 以及 Ruggiero 和 Sargeant [44] 提出了限制数据流程序空间需求的启发式方法。Burton [14] 展示了如何在不引起死锁的情况下限制某些并行计算的空间需求。最近，Burton [15] 开发并分析了一种具有可证明良好时间和空间界限的调度算法。Blelloch、Gibbons、Matias 和 Narlikar [3, 4] 也最近开发并分析了具有可证明良好时间和空间界限的调度算法。目前尚不清楚这些算法是否如工作窃取一样实用。

本文的其余部分组织如下。在第 2 节中，我们回顾了[10]中介绍的多线程计算的图论模型，该模型为分析调度器提供了理论基础。第 3 节介绍了一个使用中央队列的简单调度算法，这个 busy-leaves 算法是我们在第 4 节中提出的随机工作窃取算法的基础。在第 5 节中，我们介绍了用于分析工作窃取算法的执行时间和通信成本的原子访问模型，并展示和分析了用于推导随机工作窃取中争用界限的**“球和箱的组合游戏”（combinatorial "balls and bins game"）**。接着，我们在第 6 节中使用这一界限结合**延迟序列论证（delay-sequence argument）** [41] 来分析工作窃取算法的执行时间和通信成本。最后，在第 7 节中，我们简要讨论了本文的理论思想如何应用于 Cilk 编程语言和运行时系统 [8, 25]，并做出一些总结性评论。

# 2. 多线程计算模型（A model of multithreaded computation）

本节重述了 [10] 中介绍的多线程计算的图论模型。我们还定义了“完全严格”计算的含义。最后，我们陈述了**贪心调度定理（greedy-scheduling theorem）**，这是对 Brent [13] 和 Graham [27, 28] 关于有向无环图（DAG）调度定理的**应用（adaptation）**。

多线程计算由一组线程组成，每个线程都是**单位时间指令（unit-time instruction）**的顺序排列。指令通过**依赖边（dependency edge）**连接，这些依赖边提供了**部分顺序（partial ordering）**，指明哪些指令必须在其他指令之前执行。在图 1 中，每个阴影块代表一个线程，圆圈表示指令，水平边（称为**连续边（continue edge）**）表示顺序排列。例如，线程 \\(\Gamma_5\\) 包含3条指令：\\(v_\text{10}\\)、\\(v_\text{11}\\) 和 \\(v_\text{12}\\)。这些指令必须按照从左到右的顺序执行。为了执行一个线程，我们为它分配一块内存，称为**活动帧（activation frame）**，供线程的指令存储计算所需的值。



{% asset_img "figure_1.png" %}
**图 1**：多线程计算。这段计算包含23条指令 \\(v_\text{1}\\), \\(v_\text{2}\\),  ..., \\(v_\text{23}\\) 和 6 条线程  \\(\Gamma_1\\),  \\(\Gamma_2\\), ...,  \\(\Gamma_6\\)。

> *译注：这段提到了单位时间指令。 这里简单说下我对该术语的理解：*
> + *<strong>单位时间指令（unit-time instruction）</strong>,指的是在计算模型中，每条指令都需要一个时间单位（通常是一个时钟周期）来执行。这种假设简化了计算的分析和建模，因为可以假设所有指令的执行时间相同，从而更容易计算总执行时间和调度方案。*

一个用于多线程计算的**具有P个处理器的执行计划（P-processor execution schedule）**，对于一台具有P个处理器的并行计算机，它确定了在每一步中并行计算机中的哪个处理器执行哪些指令。执行计划依赖于特定的多线程计算和处理器数量 P。在执行计划的任何给定步骤中，每个处理器最多执行一条指令。在执行过程中，一个线程可以创建或**生成（spawn）**其他线程。**生成线程（spawning a thread）**类似于子程序调用，但不同之处在于生成线程可以与被生成的线程并发运行。我们认为被生成的线程是生成线程的子线程，一个线程可以生成任意数量的子线程。通过这种方式，线程组织成一个**生成树（spawn tree）**，如图 1 所示，向下指向的阴影依赖边称为**生成边（spawn edge）**，连接线程和它们生成的子线程。生成树是**调用树（call tree）**的并行对应物。在我们的计算示例中，整个生成树的**根（root）**是 \\(\Gamma_1\\)，它有两个子线程 \\(\Gamma_2\\) 和 \\(\Gamma_6\\)， 而 \\(\Gamma_2\\) 有三个子线程，\\(\Gamma_3\\)、\\(\Gamma_4\\) 与 \\(\Gamma_5\\)。而线程 \\(\Gamma_3\\)、\\(\Gamma_4\\)、\\(\Gamma_5\\)、\\(\Gamma_6\\)，它们没有子线程，是**叶子线程（leaf threads）**。

每个生成边（spawn edge）从父线程中的一个特定指令，即实际执行生成操作（spawn operation）的指令，指向子线程的第一条指令。执行计划必须遵循这一约束，即在父线程中的生成指令执行完毕之前，任何处理器都不能执行被生成子线程中的任何指令。在我们的计算示例中（图 1），因为生成边 \\((v_6, v_7)\\) 的存在，指令 \\(v_7\\) 在生成指令 \\(v_6\\) 执行之前不能被执行。与我们的单位时间指令模型保持一致，一条指令最多可以生成一个子线程。当生成指令执行时，它会为新生成的子线程分配一个活动帧。一旦线程被生成并且其帧被分配，我们就说该线程是**存活的（alive）**或**正在运行（living）**。当一个线程的最后一条指令执行时，它会释放其帧，之后该线程**终止（dies）**。

执行计划通常还会遵守除连续边和生成边以外的其他依赖关系。考虑一条产生数据值的指令，该数据值将被另一条指令消费。这种生产者/消费者关系阻止消费指令在生产指令之前执行。为了体现并强制执行这种顺序，可能需要其他依赖边，称为**同步边（join edges）**，即图 1 中所示的曲线边。如果一个线程在生产指令执行之前到达消费指令，消费线程的执行将无法继续 —— 线程会**停滞（stalls）**。当生产指令执行后，**同步依赖关系（join dependency）**得以**解决（resolved）**，使得消费线程可以继续执行 —— 线程变为**就绪状态（ready）**。多线程计算模型并不描述同步依赖关系如何得到解决或未解决的同步依赖关系如何被检测到。在实现过程中，解决和检测可以通过一些机制来完成，例如 join counters [8] 、futures [30] 或 I-structures [2] 。

我们对同步边提出了两个技术假设。首先，我们假设每条指令最多有常数数量的同步边。这一假设与我们的单位时间指令模型是一致的。第二个假设是，同步边不会进入生成操作之后的紧随指令。这意味着，当父线程生成一个子线程时，父线程不会立即**停滞（stall）**，它至少还能继续执行一个指令。

执行计划必须遵守生成边、连续边和同步边所规定的约束。这些依赖边形成了一个指令的有向图，且在该图中的所有前序指令都执行完毕之前，任何处理器都不能执行某条指令。为了保证执行计划的存在，这个图必须是无环的，即它必须是一个有向无环图（**DAG**）。在执行计划的任何给定步骤中，如果一个指令在 DAG 中的所有前序指令都已执行完毕，那么该指令就是就绪的。

我们做了简化假设，即父线程在所有子线程终止之前保持存活，因此线程在其所有子线程的活动帧被释放之前不会释放其自身的活动帧。尽管这个假设并非绝对必要，但它使执行过程具有**自然结构（natural structure）**，并简化了我们对空间利用的分析。在计算空间利用时，我们还假设活动帧包含计算中使用的所有值，即计算之外没有全局存储（即便如果有这样的存储，我们也不考虑它）。因此，在执行计算的任何给定时间点所使用的空间是**所有存活线程使用的活动帧的总大小**，而执行计算过程中使用的**总空间**是**整个执行过程中此值的最大值**。

总结来说，多线程计算可以看作是由依赖边连接的指令组成的有向无环图（DAG）。指令通过连续边连接成线程，线程通过生成边形成生成树。当一个线程生成时，会分配一个活动帧，并且只要线程存活，这个帧就会一直保留。存活的线程可能因为未解决的依赖关系而处于就绪或停滞状态。

一个多线程程序在给定输入下运行时，有时可能每次运行会生成不同的多线程计算。在这种情况下，我们称该程序为**非确定性的（nondeterministic）**。如果不管计算如何调度，程序在给定输入下生成的多线程计算都是相同的，则该程序是**确定性的（deterministic）**。在本文中，我们将分析多线程计算，而不是多线程程序。具体来说，我们不会关注多线程计算是如何生成的，而是从**后验的（posteriori）**角度研究其属性。

由于具有任意依赖关系的多线程计算可能无法高效地调度 [10]，我们研究了通用多线程计算的子类，其限制了其中可能发生的同步类型。**严格的多线程计算（strict multithreaded computation）**是指所有来自一个线程的同步边都指向**活动树（activation tree）**中该线程的一个祖先。在严格的计算中，进入子树的唯一边（从子树外发出）是生成子树根线程的生成边。例如，图 1 的计算是严格的，根植于 \\(\Gamma_2\\) 的子树的唯一边是生成边 \\((v2, v3)\\)。因此，**严格性（strictness）**意味着在所有参数可用之前，线程不能被调用，尽管这些参数可以并行收集。**完全严格的计算（fully strict computation）**是指**所有来自一个线程的同步边都指向该线程的父线程**。完全严格的计算在某种意义上是**“结构良好（well-structured）”**的计算，因为来自子树（生成树的一部分）的所有同步边都从子树的根发出。图 1 的示例计算是完全严格的。任何可以在单个处理器上以深度优先方式执行的多线程计算，都可以通过改变依赖结构，使其变为严格或完全严格，从而可能影响其可实现的并行性，但不影响计算的语义 [5]。

我们根据计算的**“工作量（work）”**和**“关键路径长度（critical-path length.）”**来量化和限制在 P 个处理器并行计算机上的计算执行时间。我们定义计算的工作量为指令的总数，关键路径长度为有向无环图（DAG）中最长的路径长度。我们的示例计算（图 1 ）工作量为 23，关键路径长度为 10。对于给定的计算，令 \\(T(\mathcal{X})\\) 表示使用 P 处理器执行计划 \\(\mathcal{X}\\) 执行该计算所需的时间，并令

$$ T_P = \min_{\mathcal{X}} T(\mathcal{X}) $$

表示 P 个处理器的最小执行时间——这个最小值是在所有 P 处理器执行计划中取的。然后 \\(T_1\\) 是计算整体的工作量，因为单处理器计算机每一步只能执行一条指令，而 \\(T_\infty\\) 是关键路径长度，因为即使有任意多的处理器，路径上的每条指令也必须串行执行。注意我们必须有 ，因为 P 个处理器每个时间步只能执行 P 条指令，当然，我们也必须有 \\(T_P \geq T_\infty\\)。

Brent [13] 和 Graham [27, 28] 早期关于 DAG 调度的工作表明，存在 P 处理器执行计划 \\(\mathcal{X}\\)，使得 \\(T(\mathcal{X}) \leq T_1/P + T_\infty\\)。作为两个下界的和，这个上界在一个因子 2 以内是普遍最优的。以下定理在 [10, 20] 中证明，并略微地扩展了上述这些结果，表明可以通过**贪婪调度（greedy schedules）**获得\\(T_P\\)这个上界：在执行的每一步中，如果至少有 P 条指令准备好，则执行 P 条指令，如果少于 P 条指令准备好，则全部执行。

> <i>译注：文中提到，\\(T(\mathcal{X}) \leq T_1/P + T_\infty\\) ，\\(T(\mathcal{X})\\) 作为两个下界的和，\\(T(\mathcal{X})\\)这个上界在一个因子 2 以内是普遍最优的。 </i>
> *也就是说 \\(T_P\\) 这个上界的时间在最优值的两倍以内是普遍最优的。换句话说，即使在最坏情况下，执行时间也不会超过上界时间的两倍。*

**定理1（贪婪调度定理 The greedy-scheduling theorem）** 对于具有工作量 \\(T_1\\) 和关键路径长度 \\(T_\infty\\) 的任意多线程计算，对于任意数量的处理器 \\(P\\)，任何贪婪的 \\(P\\) 处理器执行器计划 \\(\mathcal{X}\\) 都满足 \\(T(\mathcal{X}) \leq \frac{T_1}{P} + T_{\infty}\\)。

通常，我们感兴趣的是实现**线性加速（linear speedup）**的调度，即 \\(T(\mathcal{X})=O(\frac{T_1}{P})\\)。对于贪婪调度，当我们定义的**并行度（parallelism）**\\(\frac{T_1}{T_\infty}\\) 满足 \\(\frac{T_1}{T_\infty} = \Omega(P)\\) 时，就会发生。

> *译注：这里的 \\(\Omega(P)\\) 的 \\(\Omega\\) ， 是在算法复杂度中的渐近符号，一般我们大 \\(O\\) 看到的比较多，对 \\(\Omega\\) 比较陌生。*
> <i>其中 \\(O\\) 表示时间复杂度的上界， 而 \\(\Omega\\) 代表时间复杂度的下界。 当 \\(f(P) = \Omega(g(P))\\) ， 意味着存在常数 \\( c > 0 \\) 和 \\(P_0 > 0\\) ，使得所有 \\(P \geq P_0\\)， 有 \\(f(P) \geq c \cdot g(P)\\) </i>
> *在上下文中， \\(T(\mathcal{X})=O(\frac{T_1}{P})\\) 表示当处理器数量为 \\(P\\) 增加时，并行度 \\(\frac{T_1}{P}\\) 也会至少按 P 的速度增长。 这个条件保证了调度算法能够实现线性加速。*

为了量化给定计算执行计划所使用的空间，我们定义线程的**堆栈深度（stack depth）**为所有祖先的活动帧大小之和，包括它自身。多线程计算的**堆栈深度**是其任意线程的最大堆栈深度。我们将用 \\(S_1\\) 表示任意单处理器执行多线程计算所需的最小空间量，这等于计算堆栈深度。令 \\(S(\mathcal{X})\\) 表示 \\(P\\) 处理器执行计划 \\(\mathcal{X}\\) 所使用的空间。我们感兴趣的是那些展示出至多**线性空间扩展（linear expansion of space）**的执行计划，即 \\(S(\mathcal{X}) = O(S_1P)\\) ，这种情况在常数因子范围内是存在最优的 [10]。

# 3. “繁忙叶子” 线程的性质（"busy-leaves" property）

一旦线程 \\(\Gamma\\) 在严格计算中生成，即使在计算的其他部分没有进展，单个处理器也可以完成以 \\(\Gamma\\) 为根的整个子计算的执行。换句话说，从线程\\(\Gamma\\) 被生成到其结束的整个期间，以 \\(\Gamma\\) 为根的子计算中始终至少有一个线程处于就绪状态。特别地，严格多线程计算中的任何叶子线程都不会停滞。正如我们将看到的，这一性质允许执行计划保持叶子“繁忙”。通过将这一“繁忙叶子”性质与贪婪性质结合，我们推导出同时展示线性加速和线性空间扩展的执行计划。

> *译注： 这里的遵循严格计算的执行计划对应的叶子线程都不会停滞，是因为严格计算中，<strong>同步边（join edges）</strong> 都是从叶子线程指向它的祖先，也就是只有祖先线程会停滞，叶子线程自己不会。*

在本节中，我们将展示对于任意数量的处理器 \\(P\\) 和任何具有工作量 \\(T_1\\)、关键路径长度 \\(T_\infty\\) 以及堆栈深度 \\(S_1\\) 的严格多线程计算，存在一个 \\(P\\) 处理器执行计划 \\(\mathcal{X}\\)，使得时间 \\(T(\mathcal{X}) \leq \frac{T_1}{P} + T_\infty \\) 和空间 \\(S(\mathcal{X}) \leq S_1P \\) 同时成立。我们给出一个简单的在线 \\(P\\) 处理器并行算法—— **"busy-leaves"** 繁忙叶子算法——来计算这样的计划。这个简单的算法将成为第 4 节中介绍的随机工作窃取算法的基础。

繁忙叶子（Busy-Leaves）算法以如下方式在线运行。在第 \\(t\\) 步之前，算法已经计算并执行了前 \\(t-1\\) 步的执行计划。在第 \\(t\\) 步，算法仅使用迄今在执行中揭示的部分计算信息来计算并执行第 t 步的计划。特别地，它不使用尚未执行的指令或尚未生成的线程的信息。

繁忙叶子（Busy-Leaves）算法将所有活跃线程保存在一个单一的线程池中，该线程池对所有 \\(P\\) 处理器均可用。当生成操作发生时，新线程被添加到这个全局池中，当处理器需要工作时，它从池中移除一个就绪的线程。尽管我们将该算法描述为一个 \\(P\\) 处理器并行算法，但我们不会作为并行算法来分析它。具体来说，在计算第 \\(t\\) 步计划时，我们允许每个处理器向线程池中添加线程并从中删除线程。因此，我们忽略处理器争夺线程池访问的影响。实际上，我们只分析计划本身的属性，忽略算法在计算计划时产生的成本。（然而，对于随机工作窃取算法，我们将分析调度开销。）

繁忙叶子（Busy-Leaves）算法如下操作。算法以全局线程池中的根线程和所有处理器空闲状态开始。在每一步开始时，每个处理器要么空闲，要么有一个线程要处理。那些空闲的处理器开始尝试从池中移除任何就绪线程。如果池中有足够多的就绪线程满足所有空闲处理器，则每个空闲处理器获得一个就绪线程继续工作。否则，一些处理器将保持空闲。然后，每个有线程要处理的处理器执行该线程的下一条指令。一般情况下，一旦处理器有一个线程（称为 \\(\Gamma_\alpha\\)）要处理，它将在每一步执行该线程的指令，直到线程生成、停滞或结束，在这种情况下，它将按照以下规则进行操作：

1. **生成（Spawns）**：如果线程 \\(\Gamma_\alpha\\) 生成了一个子线程 \\(\Gamma_\beta\\)，处理器通过将 \\(\Gamma_\alpha\\) 返回到线程池来完成当前步骤。处理器在下一步开始处理 \\(\Gamma_\beta\\)。

2. **停滞（Stalls）**：如果线程 \\(\Gamma_\alpha\\) 停滞，处理器通过将 \\(\Gamma_\alpha\\) 返回到线程池来完成当前步骤。处理器在下一步开始时处于空闲状态。

3. **结束（Dies）**：如果线程 \\(\Gamma_\alpha\\) 结束，处理器通过检查 \\(\Gamma_\alpha\\) 的父线程 \\(\Gamma_\beta\\) 当前是否有任何存活的子线程来完成当前步骤。如果 \\(\Gamma_\beta\\) 没有存活的子线程且没有其他处理器正在处理 \\(\Gamma_\beta\\)，则处理器从池中取出 \\(\Gamma_\beta\\) 并在下一步开始处理 \\(\Gamma_\beta\\)。否则，处理器在下一步开始时处于空闲状态。

{% asset_img "figure_2.png" %}
**图2**：由繁忙叶子（Busy-Leaves）算法计算出的图 1 的 2 处理器执行计划。该计划列出了在每一步中，每个空闲处理器移除一个就绪线程之后，全局线程池中的存活线程。它还列出了每一步中每个处理器 p1 和 p2 正在处理的就绪线程和执行的指令。就绪的存活线程以粗体列出。其他存活线程则处于停滞状态。

图 2 说明了由繁忙叶子（Busy-Leaves）算法计算出的图 1 的 2 处理器执行计划中的这三条规则：
+ **规则1** ：在第 2 步，处理器 \\(p_1\\) 处理线程 \\(\Gamma_1\\) 执行 \\(v_2\\)，生成子线程 \\(\Gamma_2\\)，因此 \\(p_1\\) 将 \\(\Gamma_1\\) 放回池中（将在下一步开始时由空闲的 \\(p_2\\) 取出）并开始下一步处理 \\(\Gamma_2\\)。
+ **规则2**：在第 8 步，处理器 \\(p_2\\) 处理线程 \\(\Gamma_1\\) 执行 \\(v_\text{21}\\) 并且 \\(\Gamma_1\\) 停滞，所以 \\(p_2\\) 将 \\(\Gamma_1\\) 返回到池中并在下一步开始时空闲（并且保持空闲状态，因为线程池中没有就绪的线程）。
+ **规则3**：在第 13 步，处理器 \\(p_1\\) 处理 \\(\Gamma_2\\) 执行 \\(v_\text{15}\\) 并且 \\(\Gamma_2\\) 结束，所以 \\(p_1\\) 从池中取出父线程 \\(\Gamma_1\\) 并开始下一步处理 \\(\Gamma_1\\)。

除了是贪婪的，对于任何严格计算，由繁忙叶子（Busy-Leaves）算法计算出的计划保持**繁忙叶子性质（Busy-Leaves property）**：在执行过程中的每一个时间步，"生成子树"中的每一个叶子都有一个处理器在处理它。我们将任意时间步 \\(t\\) 的生成子树定义为<strong>由那些在 \\(t\\) 步存活的线程组成的生成树部分</strong>。重申繁忙叶子性质，在每一个时间步，每一个没有存活后代的存活线程都有一个处理器在处理它。我们现在将证明这一事实并表明它意味着线性空间扩展。值得注意的是，并不是每个多线程计算都有一个保持繁忙叶子性质的计划，但每个严格多线程计算都有。我们首先展示任何保持繁忙叶子性质的计划表现出线性空间扩展。

**引理2（Lemma 2）**：对于任何堆栈深度为 \\(S_1\\) 的多线程计算，任何保持繁忙叶子性质的 \\(P\\) 处理器执行计划 \\(\mathcal{X}\\) 使用的空间由 \\(S(\mathcal{X}) \leq S_1P \\) 界定。

**证明（Proof）**：繁忙叶子性质意味着在所有时间步 \\(t\\) 上，生成子树最多有 \\(P\\) 个叶子。对于每个这样的叶子，它及其所有祖先使用的空间最多为 \\(S_1\\)，因此，任何时间步 \\(t\\) 使用的空间最多为 \\(S_1P\\)。

对于保持繁忙叶子性质的执行计划，上界 \\(S_1P\\) 是保守的。通过为每个繁忙叶子**分配（charging）** \\(S_1\\) 空间，我们可能会**过度分配（overcharging）**。对于某些计算，通过知道计划保持繁忙叶子性质，我们可以直接诉诸生成子树从未超过 \\(P\\) 个叶子的事实来获得紧的空间使用界。

我们通过展示对于严格计算，繁忙叶子（Busy-Leaves）算法计算出的计划既是贪婪的又保持繁忙叶子性质来结束本节。

**定理3**：对于任意数量的处理器 \\(P\\) 和任何具有工作量 \\(T_1\\)、关键路径长度 \\(T_\infty\\) 以及堆栈深度 \\(S_1\\) 的严格多线程计算，繁忙叶子算法计算出一个 \\(P\\) 处理器执行计划 \\(\mathcal{X}\\)，其执行时间满足 \\(T(\mathcal{X}) \leq T_1/P + T_\infty\\)，其空间满足 \\(S(\mathcal{X}) \leq S_1P \\)。

**证明（Proof）**： 时间界直接从贪婪调度定理（定理1）得出，因为繁忙叶子（Busy-Leaves）算法计算出一个贪婪调度计划。空间界来自引理2，如果我们可以证明繁忙叶子算法（Busy-Leaves）保持繁忙叶子性质。我们通过对步骤数的归纳证明这一事实。在算法的第一步，生成子树仅包含根线程，它是一个叶子线程，并且有处理器在处理它。我们必须证明所有算法规则都保持繁忙叶子性质。当处理器有一个线程 \\(\Gamma_\alpha\\) 要处理时，它执行该线程的指令，直到它生成、停滞或结束，则有：

+ **规则1** ：如果 \\(\Gamma_\alpha\\) 生成了一个子线程 \\(\Gamma_\beta\\)，则 \\(\Gamma_\alpha\\) 不是叶子线程（即使它之前是）并且 \\(\Gamma_\beta\\) 是叶子线程。在这种情况下，处理器处理 \\(\Gamma_\beta\\)，因此新叶子线程是繁忙的。
+ **规则2** ：如果 \\(\Gamma_\alpha\\) 停滞，则 \\(\Gamma_\alpha\\) 不能是叶子线程，因为在严格计算中，未解决的依赖必须来自后代。
+ **规则3** ：如果 \\(\Gamma_\alpha\\) 结束，则其父线程 \\(\Gamma_\beta\\) 可能变成叶子。在这种情况下，处理器处理 \\(\Gamma_\beta\\)，除非有其他处理器已经在处理它，因此新的叶子线程保证是繁忙的。

我们现在知道每个严格多线程计算都有一个高效的执行计划，并且我们知道如何找到它。但这些事实只能带我们到这里。执行计划必须高效地在线计算，尽管繁忙叶子算法确实计算出高效的执行计划并在线运行，但它肯定不会高效运行，除非在小规模对称多处理器的情况下。这种缺乏可扩展性是由于**采用了单一的集中线程池，所有处理器必须争夺访问**。下一节中，我们提出一个分布式在线调度算法，并在接下来的几节中证明它既高效又可扩展。

# 4. 随机工作窃取算法 （A randomized work-stealing algorithm）

在本节中，我们介绍了一种用于在并行计算机上调度多线程计算的在线随机工作窃取算法。同时，我们提出了一个重要的结构性引理，在本节末尾用于证明对于完全严格的计算，该工作窃取b算法最多只会导致线性空间扩展。该引理在第6节中再次出现，证明对于完全严格的计算，该算法实现了**线性加速并产生了存在性最优的通信量**。

在工作窃取算法中，繁忙叶子（Busy-Leaves）算法的集中线程池分布在各处理器上。具体来说，每个处理器维护一个线程的**就绪双端队列（ready deque）**数据结构。就绪双端队列有两个端：顶端和底端。线程可以从底端插入，并可以从任一端移除。处理器将其就绪双端队列视为调用栈，从底端推入和弹出。而迁移到其他处理器的线程从顶端移除。

> *译注： P 个处理器维护自己的双端队列，从这里能看出来 Golang 调度器 G-M-P 的影子了（只不过 Golang 维护的协程，论文是围绕线程在讲）*

一般来说，处理器通过移除其就绪双端队列底部的线程来获取工作。它开始处理该线程，称为 \\(\Gamma_\alpha\\)，并继续执行 \\(\Gamma_\alpha\\) 的指令，直到 \\(\Gamma_\alpha\\) 生成、停滞、结束或激活一个停滞的线程，在这种情况下，它根据以下规则进行操作：

1. **生成**： 如果线程  \\(\Gamma_\alpha\\) 生成了一个子线程  \\(\Gamma_\beta\\)，那么  \\(\Gamma_\alpha\\) 被放置在就绪双端队列的底部，处理器开始处理  \\(\Gamma_\beta\\)。
2. **停滞**： 如果线程 \\(\Gamma_\alpha\\) 停滞，其处理器检查其就绪双端队列的顶端。如果就绪双端队列中有线程，处理器将移除并开始处理最底部的线程。然而，如果就绪双端队列为空，处理器将开始工作窃取：它从随机选择的处理器的就绪双端队列中窃取最顶端的线程并开始处理它。（下面将详细说明这种工作窃取策略。）
3. **结束**：如果线程 \\(\Gamma_\alpha\\) 结束，则处理器按照规则2进行操作，就像 \\(\Gamma_\alpha\\) 停滞一样。
4. **激活**：如果线程 \\(\Gamma_\alpha\\) 激活了一个停滞的线程 \\(\Gamma_\beta\\)，则现在就绪的线程 \\(\Gamma_\beta\\) 被放置在 \\(\Gamma_\alpha\\) 处理器的就绪双端队列的底部。

一个线程可以同时激活一个停滞的线程并停滞或结束，在这种情况下，我们首先执行规则 4 以激活，然后执行规则 2 以停滞或规则 3 以结束。除了规则 4 用于激活停滞线程的情况，这些规则与繁忙叶子算法的规则类似，正如我们将看到的，规则 4  是确保算法保持重要结构性特性（包括繁忙叶子特性）所必需的。

工作窃取算法以所有就绪双端队列为空开始。多线程计算的根线程被放置在一个处理器的就绪双端队列中，而其他处理器开始工作窃取。

当处理器开始工作窃取时，它按以下方式操作。处理器变成一个“窃贼”，并尝试从随机选择的受害者处理器窃取工作。“窃贼”查询“受害者”的就绪双端队列，如果它非空，“窃贼”移除并开始处理顶端的线程。如果“受害者”的就绪双端队列为空，“窃贼”将再次尝试，从随机选择的另一个“受害者”那里窃取。

我们现在陈述并证明一个关于在完全严格计算执行期间，任何处理器的就绪双端队列中线程结构的重要引理。这个引理在本节后面用于分析执行空间，并在第 6 节中用于分析执行时间和通信。图 3 说明了这个引理：

{% asset_img "figure_3.png" %}
**图 3** ：处理器的就绪双端队列结构。每个线程中的黑色指令表示该线程当前的就绪指令。只有线程 \\(\Gamma_k\\) 可能在上次生成子线程后被处理过。虚线边是将在第 6 节中介绍的**“双端队列边”（deque edges）**。

**引理 4（Lemma 4）**：在由工作窃取算法执行的任何**完全严格**多线程计算中，考虑任意处理器 \\(p\\) 以及 \\(p\\) 在某个时间步上正在处理的线程。设 \\(\Gamma_0\\) 为 \\(p\\) 正在处理的线程，设 \\(k\\) 为 \\(p\\) 的就绪双端队列中线程的数量，并设 \\(\Gamma_1\\), \\(\Gamma_2\\), ..., \\(\Gamma_k\\) 表示按从底到顶顺序排列的 \\(p\\) 的就绪双端队列中的线程。因此 \\(\Gamma_1\\) 是最底部的线程，而 \\(\Gamma_k\\) 是最顶端的。如果 \\(k\\) > 0，则 \\(p\\) 的就绪双端队列中的线程满足以下性质：

1. 对于 \\(i = 1, 2, ..., k\\)，线程 \\(\Gamma_i\\) 是 \\(\Gamma_{i-1}\\) 的父线程。
2. 如果 \\(k > 1\\)，则对于 \\(i = 1, 2, ..., k-1\\)，自从生成 \\(\Gamma_{i-1}\\) 以来，线程 \\(\Gamma_i\\) 尚未被处理。

**证明**：证明是基于执行时间的直接归纳。执行开始时，某个处理器的就绪双端队列中有根线程，所有其他就绪双端队列为空，因此引理在一开始是**显然成立（vacuously holds）**的。现在，考虑算法的任意步骤，其中处理器 \\(p\\) 执行线程 \\(\Gamma_0\\) 的指令。设 \\(\Gamma_1\\), \\(\Gamma_2\\), ..., \\(\Gamma_k\\) 表示步骤前 \\(p\\) 的就绪双端队列中的 \\(k\\) 个线程，并假设 \\(k = 0\\) 或两个性质都成立。设 \\(\Gamma_0'\\) 表示步骤后 \\(p\\) 正在处理的线程，并设 \\(\Gamma_1'\\), \\(\Gamma_2'\\), ..., \\(\Gamma_\text{k'}'\\) 表示步骤后 \\(p\\) 的就绪双端队列中的 \\(k'\\) 个线程。我们现在看算法规则，并证明它们都保持引理成立。也就是说，\\(k' = 0\\) 或两个性质都成立。

+ **规则 1**：如果 \\(\Gamma_0\\) 生成了一个子线程，那么 \\(p\\) 将 \\(\Gamma_0\\) 推入就绪双端队列的底部并开始处理子线程。这个子线程是 \\(\Gamma_0'\\)，我们有 \\(k' = k + 1 > 0\\)，并且对于 \\(j = 1, 2, ..., k'\\)，我们有 \\(\Gamma_j' = \Gamma_\text{j-1}\\)。参见图 4。现在我们可以检查两个性质：
  + **性质 1**：如果 \\(k' > 1\\)，那么对于 \\(j = 2, 3, ..., k'\\)，线程 \\(\Gamma_j'\\) 是 \\(\Gamma_\text{j-1}'\\) 的父线程，因为生成发生在 \\(k > 0\\)，这意味着对于 \\(i = 1, 2, ..., k\\)，线程 \\(\Gamma_i\\) 是 \\(\Gamma_\text{i-1}\\) 的父线程。此外，\\(\Gamma_1'\\) 显然是 \\(\Gamma_0'\\) 的父线程。
  + **性质 2**：如果 \\(k' > 2\\)，则对于 \\(j = 2, 3, ..., k'-1\\)，线程 \\(\Gamma_j'\\) 自从生成\\(\Gamma_\text{j-1}'\\) 后尚未被处理，因为在生成之前我们有 \\(k > 1\\)，这意味着对于 \\(i = 1, 2, ..., k-1\\)，线程 \\(\Gamma_i\\) 自从生成 \\(\Gamma_\text{i-1}\\) 后尚未被处理。最后，线程 \\(\Gamma_1'\\) 自从生成 \\(\Gamma_0'\\) 后尚未被处理，因为生成刚刚发生。

{% asset_img "figure_4.png" %}
**图 4**： 处理器在工作线程 \\(\Gamma_0\\) 生成子线程前后的就绪双端队列。（注意，线程 \\(\Gamma_0\\) 和 \\(\Gamma_0'\\) 实际上并不在双端队列中；它们是在生成前后正在处理的线程。）

+ **规则 2 和 3**： 如果 \\(\Gamma_0\\) 停滞或结束，那么我们有两种情况需要考虑。
  + 如果 \\(k = 0\\)，就绪双端队列为空，因此处理器开始工作窃取，当处理器窃取并开始处理一个线程时，我们有 \\(k' = 0\\)。
  + 如果 \\(k > 0\\)，就绪双端队列不为空，因此处理器从双端队列中弹出最底部的线程并开始处理它。因此，我们有 \\(\Gamma_0' = \Gamma_1\\)（弹出的线程）并且 \\(k' = k - 1\\)，对于 \\(j = 1, 2, ..., k'\\)，我们有\\(\Gamma_j' = \Gamma_\text{j+1}\\)。见 图 5。
  现在，如果 \\(k' > 0\\)，我们可以检查两个性质。
  + **性质 1**：对于 \\(j = 1, 2, ..., k'\\)，线程 \\(\Gamma_j'\\) 是 \\(\Gamma_\text{j-1}'\\) 的父线程，因为对于 \\(i = 1, 2, ..., k\\)，线程 \\(\Gamma_i\\) 是 \\(\Gamma_\text{i-1}\\) 的父线程。
  + **性质 2**：如果 \\(k' > 1\\)，则对于 \\(j = 1, 2, ..., k' - 1\\)，线程 \\(\Gamma_j'\\) 自从生成 \\(\Gamma_\text{j-1}'\\) 后尚未被处理，因为在停滞或结束之前我们有 \\(k > 2\\)，这意味着对于 \\(i = 2, 3, ..., k-1\\)，线程  \\(\Gamma_i\\) 自从生成\\(\Gamma_\text{i-1}\\) 后尚未被处理。

{% asset_img "figure_5.png" %}
**图 5**：处理器在正在处理的线程 \\(\Gamma_0\\) 结束前后的就绪双端队列。（注意，线程 \\(\Gamma_0\\) 和 \\(\Gamma_0'\\) 实际上不在双端队列中；它们是在结束前后正在处理的线程。）

+ **规则 4**：如果 \\(\Gamma_0\\) 激活了一个停滞的线程，那么由于完全严格的条件，之前停滞的线程必须是 \\(\Gamma_0\\) 的父线程。首先，我们观察到我们必须有 \\(k = 0\\)。如果我们有 \\(k > 0\\)，那么处理器的就绪双端队列不为空，并且这个父线程必须位于就绪双端队列的底部。因此，这个父线程是就绪的，规则 4 不适用。当 \\(k = 0\\) 时，就绪双端队列为空，处理器将父线程放在就绪双端队列的底部。我们有 \\(\Gamma_0' = \Gamma_0\\) 且 \\(k' = k + 1 = 1\\)，其中 \\(\Gamma_1'\\) 表示新激活的父线程。我们只需要检查第一个性质。**性质 1**：线程 \\(\Gamma_1'\\) 显然是 \\(\Gamma_0'\\) 的父线程。

如果另一个处理器从处理器 \\(p\\) 窃取了一个线程，那么我们必须有 \\(k > 0\\)，窃取后我们有 \\(k' = k - 1\\)。如果 \\(k' > 0\\) 成立，那么两个性质都明显保持。处理器 \\(p\\) 的所有其他操作 —— 例如工作窃取或执行不涉及上述任何规则的指令 —— 都显然保持引理成立。

在继续之前，值得指出的是，线程 \\(\Gamma_k\\) 自从生成 \\(\Gamma_\text{k-1}\\) 后可能已经被处理过，因为性质 2 排除了 \\(\Gamma_k\\)。这种情况发生在 \\(\Gamma_k\\) 从处理器 \\(p\\) 被窃取后并在其新处理器上停滞。后来，\\(\Gamma_k\\) 被 \\(\Gamma_\text{k-1}\\) 重新激活并带回到处理器 \\(p\\) 的就绪双端队列。关键的观察是，当 \\(\Gamma_k\\) 被重新激活时，处理器 \\(p\\) 的就绪双端队列为空，并且 \\(p\\) 正在处理  \\(\Gamma_\text{k-1}\\) 。图 3 中显示的其他线程  \\(\Gamma_\text{k-2}\\) ,  \\(\Gamma_\text{k-3}\\) , ...,  \\(\Gamma_0\\)  是在  \\(\Gamma_k\\)  被重新激活后生成的。

我们通过界定工作窃取算法在执行完全严格计算时使用的空间来结束本节。

**定理 5（Theorem 5）**：对于任何堆栈深度为 \\(S_1\\) 的完全严格多线程计算，在具有 \\(P\\) 个处理器的计算机上运行的工作窃取算法使用的空间最多为 \\(S_1P\\)。

**证明**：与繁忙叶子算法一样，工作窃取算法保持繁忙叶子性质：在执行的每一个时间步，当前生成子树中的每一个叶子都有一个处理器在处理它。如果我们能够建立这一事实，那么我们可以通过引理 2 完成证明。

工作窃取算法保持繁忙叶子性质是**引理 4** 的一个简单结果。在每一个时间步，当前生成子树中的每一个叶子必须是就绪的，因此必须要么有一个处理器在处理它，要么在某个处理器的就绪双端队列中。同时引理 4 保证没有叶子线程在处理器处理其他线程时呆在处理器的就绪双端队列中。

在已经得出空间界限的情况下，我们现在转向分析工作窃取算法的时间和通信的界限。然而，在进行这种分析之前，我们必须小心地定义一个模型，以应对多个“窃贼”处理器同时尝试从同一个“受害者”那里窃取时可能出现的竞争。

# 5. 原子访问与回收游戏（Atomic accesses and the recycling game）

本节介绍了**“原子访问（atomic-access）”**模型，我们用它来分析工作窃取算法在多线程计算执行期间的争用。我们引入了一个**组合的“球和箱”（combinatorial "balls and bins"）**游戏，用于界定在该模型中随机、异步访问所引起的总延迟量。我们将在第 6 节使用本节的结果，分析工作窃取算法。

原子访问模型是我们用来分析工作窃取算法的机器模型。我们假设机器是一台具有 P 个处理器的异步并行计算机，其内存可以是分布式的或共享的。我们的分析假设对同一数据结构的并发访问由**对手（adversary）**按顺序排队，类似于[36]的原子消息传递模型。这一假设比 Karp 和 Zhang [33] 的模型更严格。他们假设，如果对一个双端队列同时发出窃取请求，在一个时间步中，一个请求被满足，所有其他请求被拒绝。在原子访问模型中，我们也假设一个请求被满足，但其他请求由对手排队而不是被拒绝。此外，在给定双端队列的等待请求集合中，对手可以选择哪个请求被服务，哪个继续等待。对对手的唯一约束是，如果至少有一个请求针对双端队列，那么对手不能选择不服务任何请求。

> *译注： 这里的**对手（adversary）**，我理解指的是一个假想的实体或机制，它控制并管理对同一数据结构的并发访问顺序。具体来说，在原子访问模型中，对手负责安排和处理器对同一数据结构的并发请求。这种安排是按顺序进行的，即对手将所有并发请求放入一个队列中，然后按顺序处理这些请求。 对手的角色是为了模拟和分析最坏情况下的争用情况，这样可以确保在任何情况下算法都能有效地处理并发访问。因此，对手是指在模型中控制并管理请求处理顺序的假想实体。*

本节的主要结果是表明，如果 P 个处理器随机地对 P 个双端队列发出请求，并且每个处理器最多允许一个未完成的请求，那么处理器等待请求被满足的总时间可能与总请求数 M 成正比，无论哪个处理器发出请求，也无论请求如何随时间分布。为了证明这一结果，我们引入了一个**“球和箱（balls and bins）”**游戏，模拟对手的排队效果。

**(P, M)-回收游戏**是一个由对手进行的组合游戏，其中球被随机投到箱子里。参数 P 是游戏中的球的数量，等于箱子的数量。参数 M 是对手执行的总投球次数。最初，所有 P 个球在一个与 P 个箱子分开的**存储区（reservoir）**中。在游戏的每一步，对手按顺序执行以下两个操作：

1. 对手选择存储区中的一些球（可能全部，也可能一个都不选），然后对于每个球，对手将其从存储区中取出，均匀且独立地随机选择 P 个箱子之一，并将球投进去。
2. 对手依次检查每个箱子，对于每个至少包含一个球的箱子，对手从中取出任何一个球并将其放回存储区。

对手可以进行总共 M 次投球。当 M 次投球完成且所有球都从箱子中取出并放回存储区时，游戏结束。

回收游戏模拟了工作窃取算法对窃取请求的处理。我们可以视为每个处理器都拥有一个对应的箱子和球。如果一个球在存储区中，这意味着该球的拥有者没有发出窃取请求。如果一个球在箱子中，这意味着该球的拥有者已经向箱子的拥有者的双端队列发出了窃取请求，但该请求尚未得到满足。当一个球从箱子中取出并返回存储区时，这意味着请求已被满足。

在游戏的每一步 \\(t\\) 之后，有一些数量为 \\(n_t\\) 的球留在箱子里，这些球对应于尚未满足的窃取请求。我们将关注总延迟 \\(D = \sum_{t=1}^{T} n_t\\)，其中 T 是游戏的总步数。对手的目标是使总延迟尽可能大。下一个引理表明，尽管对手在选择将哪些球投入箱子以及哪些球返回储存区时做出了选择，但总延迟不太可能很大。

**引理6（Lemma 6）**：对于任何 \\(\epsilon > 0 \\)，以至少 \\(1 − \epsilon\\) 的概率，(P, M)-回收游戏中的总延迟为 \\(O(M + PlgP + Plg(1/ε))\\)。期望总延迟最多为 \\(M\\)。换句话说，在原子访问模型中，由 \\(P\\) 个处理器发出的 \\(M\\) 个随机请求导致的总延迟以至少 \\(1 − \epsilon\\) 的概率为 \\(O(M + PlgP + Plg(1/ε))\\)，期望总延迟最多为 \\(M\\)。

**证明**：我们首先观察到，对手选择从每个箱子中取出一个球的策略是无关紧要的，因此，我们可以假设球在其箱子中按先进先出（FIFO）顺序排队。对手从队列前面取出球，当对手投掷一个球时，它被放置在队列的后面。如果在同一步中有几个球被投掷到同一个箱子里，它们可以按任何顺序放置在队列的后面。假设球在箱子中按 FIFO 纪律排队不会影响总延迟的原因是，在给定步中，无论从箱子里取出哪个球，给定箱子中的球的数量总是相同的，而球被投掷到哪里与哪个球被投掷无关。

对于任何给定的球和任何给定的步骤，该步骤要么以球在箱子中结束，要么在储存区中结束。定义球 \\(r\\) 的**延迟（delay）**为随机变量 \\(\delta_r\\)，表示球 \\(r\\) 在箱子中结束的总步数。然后，我们有 (等式 1)：

$$ D = \sum_{r=1}^{P} \delta_r $$

我们定义球的第 \\(i\\) 个**周期（cycle）**为从第 \\(i\\) 次投掷到返回储存区的步骤。还定义球的第 \\(i\\) 次**延迟（delay）**为其第 \\(i\\) 个周期中的步数。

我们将通过集中分析球 1 的延迟 \\(\delta = \delta_1\\) 来分析总延迟。如果我们让 \\(m\\) 表示对手投掷球 1 的次数，对于 \\(i = 1, 2, ..., m\\)，让 \\(d_i\\) 是表示球 1 第 i 次延迟的随机变量，那么我们有 \\(\delta = \sum_{i=1}^{m} d_i\\)

我们说球 1 的第 \\(i\\) 个周期被另一个球 \\(r\\) **延迟（delayed）**，如果球 1 的第 \\(i\\) 次投掷将其放置在某个箱子 \\(k\\) 中，而球 \\(r\\) 在球 1 的第 \\(i\\) 个周期内从箱子 \\(k\\) 中取出。由于对手遵循 FIFO 规则，因此球 1 的第 \\(i\\) 个周期可能会被另一个球 \\(r\\) 延迟一次或根本没有延迟。因此，我们可以将每个随机变量 \\(d_i\\) 分解为指示随机变量的和 \\(d_i = x_\text{i2} + x_\text{i3} + ... + x_\text{im}\\)，其中

$$
x_{ir} =
\begin{cases}
  1 & \text{如果球 1 被球 $r$ 在第 i 个周期延迟} \\\\
  0 & \text{球 1 没有被球 r 延迟}
\end{cases}
$$

因此，我们有 (等式 2): 

$$ \delta = \sum_{i=1}^{m} \sum_{r=2}^{P} x_{ir} $$


我们现在证明这些**指示随机变量（indicator random variables）**的一个重要性质。考虑任意一组 \\(S\\) 的对 \\((i, r)\\)，每个对都对应于球 1 的第 \\(i\\) 次周期被球 \\(r\\) 延迟的事件。对于任何这样的集合 \\(S\\)，我们声明 (不等式 3)：

$$ \Pr \left\\{ \bigwedge_{(i,r) \in S} (x_{ir} = 1) \right\\} \leq P^{-|S|} $$

> <i>译注：指示随机变量（indicator random variables）是一种特殊类型的随机变量，用于表示某个事件是否发生。 </i>
> <i>不等式 3 表达了指示随机变量的联合概率的上界。可能对于大部分我们研发同学比较陌生，这里解释各个符号的含义如下：</i>
> <i>\\(\Pr\\): 这是概率符号，表示后面时间发生的概率</i>
> <i>\\(\bigwedge\\): 这是逻辑与符号，表示联合事件。这里的 \\( \bigwedge_{(i,r) \in S} \\) 表示对于集合 \\(S\\) 中的所有对 \\(i, r\\), 事件 \\((x_\text{ir} = 1)\\) 都发生 </i>
> <i>\\((x_\text{ir} = 1)\\): 这是指示随机变量 \\(x_\text{ir}\\) 的取值。 它等于 1 表示第 i 次周期中的球 1 被球 r 延迟</i>
> <i>\\(\leq P^{-|S|}\\): 是联合事件的概率的上界。这里的 \\(P^{-|S|}\\) 是概率的一个上界，表示这个联合事件的概率不会超过 \\(P^{-|S|}\\)，其中 \\(|S|\\) 是集合 \\(S\\) 中对的数量</i>
> <i>简而言之，这个不等式表示，对于任何一组事件 \\(i, r\\)， 即球 1 的第 i 次周期被球 r 延迟的事件，其联合发生的概率不超过 \\(P\\) 的负 \\(|S|\\) 次方。</i>


证明这一声明的关键是要证明 （不等式 4）：

$$ \Pr \left\\{ x_{ir} = 1 \mid \bigwedge_{(i',r') \in S'} (x_{i'r'} = 1) \right\\} \leq 1/P $$

其中 \\(S' = S - {(i, r)}\\)，因此不等式（3）可以从**贝叶斯定理（Bayes's Theorem）**中得出。

> <i>译注： 在不等式 4 中，与不等式 3 的重要区别是 | 符号，这是条件概率符号，表示在某些条件下的概率</i>
> <i>简而言之，不等式 4 表示，在集合 \\(S'\\) 中所有事件（即球 1 的其他周期被其他球延迟的事件）都发生的条件下，球 1 的第 i 次周期被 r 延迟的条件概率不会超过 \\(1/P\\)</i>

我们可以通过对依赖关系的仔细分析推导出不等式（4）。因为对手遵循 FIFO 规则，我们有 \\(x_\text{ir} = 1\\) 仅当对手执行球 1 的第 i 次投掷时，它落入包含球 r 的箱子中（如果有的话）。事先，这一事件发生的概率是 1/P 或 0，因此，概率最多是 1/P。我们现在通过两种情况来论证，对球 r 与哪些球延迟了球 1 的周期或其他周期相关的任何事件进行**条件化（conditioning）**，都不会增加这个概率。

在第一种情况下，指示随机变量 \\(x_\text{i'r'}\\)，其中 \\(i' ≠ i\\)，表示球 1 的其他循环是否延迟。这些信息不能说明球 1 的第 i 次投掷的位置。因此，这些随机变量是独立于 \\(x_\text{ir}\\) 的，因此，概率上限 \\(1/P\\) 不受影响。在第二种情况下，指示随机变量 \\(x_\text{ir'}\\) 表示球 1 的第 i 次投掷是否进入包含球 r' 的箱子，但这些信息不能说明它是否进入包含球 r 的箱子，因为指示随机变量不能说明球 r 和球 r' 的位置。此外，指示随机变量之间没有更多**互相关联或协同作用（collusion）**的信息，因此不等式 4 成立。

等式 2 表明，球 1 在其所有周期中遇到的延迟 \\(\delta\\) 可以表示为 \\(m(P - 1)\\) 个指示随机变量的和。为了使 \\(\delta\\) 等于或超过给定值 \\(\Delta\\)，必须有包含 \\(\Delta\\) 个这些指示随机变量的集合，每个都必须为 1。对于任何这样的特定集合，不等式 3 表示该集合中所有随机变量都为 1 的概率至多为 \\(P^{-\Delta}\\)。由于有 \\( \binom{m(P-1)}{\Delta} \leq \left\( \frac{emP}{\Delta} \right\)^{\Delta} \\) 这样的集合，其中 e 是自然对数的底，我们有 

$$ 
\Pr \left\\{ \delta \geq \Delta \right\\} \leq \left\( \frac{emP}{\Delta} \right\)^{\Delta} P^{-\Delta} \\\\
= \left\( \frac{em}{\Delta} \right\)^{\Delta} \\\\
\leq \frac{\epsilon}{P},
$$

当 \\(\Delta \geq \max \left\\{ 2em, P + \log (1/\epsilon) \right\\}\\) 时。

<i>译注：没整明白上述两个不等式是怎么来的，也尝试套了斯特林公式。**希望有大佬能解答下**</i>


尽管我们的分析是针对球 1 进行的，但它同样适用于其他任何球。因此，对于任何一个被抛掷 \\(m_r\\) 次的球 r，其延迟 \\(\delta_r\\) 超过 \\(\max \left\\{2em_r, lg P + lg(1/\epsilon) \right\\}\\) 的概率最多为 \\(\epsilon / P\\)。通过**布尔不等式（Boole's inequality）**和<strong>等式(1)</strong>，可得出总延迟 \\(D\\) 至少以概率 \\(1 - \epsilon\\) 不超过

$$ 
D \leq \sum_{r=1}^P \max \left\\{2em_r, \lg P + \lg(1/\epsilon) \right\\} \\\\
= \Theta (M + P \lg P + P \lg(1/\epsilon) )
$$

在这里，\\( M = \sum_{r=1}^P m_r \\)

上界 \\(\mathbb{E}[D]\\) 可以如下获得（*译注：\\(\mathbb{E}[D]\\) 是指 \\(D\\) 的期望*）。回忆一下，每个 \\(\delta_r\\) 是 \\((P - 1) m_r\\) 个指示随机变量的和，每个变量的期望值最多为 \\(1/P\\)。因此，根据**期望的线性性质（inearity of expectation）**，有 \\(\mathbb{E}[\delta_r] \leq m_r \\)。 使用**等式(1)** 并再次利用期望的线性性质，我们得到 \\(\mathbb{E}[D] \leq M \\)。

有了这个关于 M 个随机请求引起的总延迟的上界，我们回到工作窃取算法。

# 6. 工作窃取算法的分析（Analysis of the workstealing algorithm）

在本节中，我们将分析使用工作窃取算法执行完全严格多线程计算的时间和通信成本。对于任何具有工作 \\(T_1\\) 和关键路径长度 \\(T_\infty\\) 的完全严格计算，我们将证明使用 P 个处理器（包括调度开销）的预期运行时间为 \\(T_1/P + O(T_\infty)\\)。此外，对于任意 \\(\epsilon > 0\\)，P 个处理器的执行时间为 \\(T_1/P + O(T_\infty + lg P + lg(1/\epsilon))\\)，概率至少为 1 - ε。我们还证明了在执行完全严格计算期间，预期的总通信量为 \\(O(PT_\infty(1+n_d)S_\text{max})\\)，其中 \\(n_d\\) 是任何线程与其父线程同步的最大次数，\\(S_{max}\\) 是任意活动帧的最大大小。

与繁忙叶子（Busy-leaves）算法不同，工作窃取算法中的**“准备池”（ready pool）**是分布式的，因此没有在集中数据结构上的那种争用。然而，当多个“窃取者”同时访问同一个“受害者”时，仍然可能发生争用。在这种情况下，正如我们在上一节中所指出的，我们做出保守的假设，即对手串行排队处理工作窃取请求。我们进一步假设处理器响应工作窃取请求的时间为一个单位时间。这个假设可以放宽而不会实质性地影响结果，因此工作窃取响应需要任意常数时间。

为了分析使用工作窃取算法在具有 P 个处理器的计算机上执行具有工作 \\(T_1\\) 和关键路径长度 \\(T_\infty\\)  的完全严格多线程计算的运行时间，我们使用了一种**记账方法（accounting argument）**。在算法的每一步，我们收集 P 美元，从每个处理器收集一个。在每一步，每个处理器根据其在该步骤中的操作将其美元放入三个桶中的一个。如果处理器在该步骤中执行指令，则将其美元放入**工作桶（WORK Bucket）**中。如果处理器在该步骤中启动了窃取尝试，则将其美元放入**窃取桶（STEAL Bucket）**中。而如果处理器仅仅等待排队的窃取请求，则将其美元放入**等待桶（WAIT Bucket）**中。我们将在执行结束时通过给出每个桶中的美元数上限来推导运行时间界限，将这三个界限相加，然后除以 P。

我们首先给出工作桶中美元总数的上限。

**引理 7（Lemma 7）**：在具有 P 个处理器的计算机上，使用工作窃取算法执行具有工作 \\(T_1\\) 的完全严格多线程计算，以恰好 \\(T_1\\) 美元结束在工作桶中。

**证明**：处理器仅在执行指令时才将美元放入工作桶中。因此，由于计算中有 \\(T_1\\) 条指令，执行结束时工作桶中恰好有 \\(T_1\\) 美元。

给出窃取桶中美元总数的上限需要一个更复杂的**“延迟序列（delay-sequence）”**论证。我们首先引入“**轮次（round）**”的概念，并且我们还必须定义一个增强的 DAG，然后用它来定义**“关键（critical）”**指令。其思路如下。如果在执行过程中尝试了大量窃取操作，那么我们可以在增强的 DAG 中识别出一系列指令 —— 延迟序列，这些窃取尝试中的每一个都是在序列中的某些指令是关键时发起的。然后我们证明，在适度数量的窃取尝试中，关键指令不太可能保持关键。我们可以得出结论，这样的延迟序列不太可能发生，因此，执行不太可能遭受大量的窃取尝试。

窃取尝试的一个轮次是一组至少 \\(3P\\) 但少于 \\(4P\\) 的连续窃取尝试，这样，如果在时间步 \\(t\\) 发起的窃取尝试发生在特定的轮次中，那么在时间步 \\(t\\) 发起的所有其他窃取尝试也在同一轮次中。我们可以将执行期间发生的所有窃取尝试划分为如下的轮次。第一轮包含在时间步 \\(1, 2, …, t_1\\) 发起的所有窃取尝试，其中 \\(t_1\\) 是最早的时间，使得在 \\(t_1\\) 之前或在 \\(t_1\\) 发起的窃取尝试至少为 \\(3P\\)。我们说第一轮在时间步 1 开始并在时间步 \\(t_1\\) 结束。通常，如果第 i 轮在时间步 \\(t_i\\) 结束，则第 \\((i+1)\\) 轮在时间步 \\(t_i+1\\) 开始并在时间步 \\(t_{i+1}\\) 结束，此时至少在 \\(t_i + 1\\) 和 \\(t_{i+1}\\) 之间（含）的时间步发起了至少 \\(3P\\) 次窃取尝试。这些窃取尝试属于第 \\(i+1\\) 轮。根据定义，每轮至少包含 \\(3P\\) 连续窃取尝试。由于在单个时间步内，每个处理器最多可以发起一次窃取尝试，所以在一个时间步内最多可以有 \\(P-1\\) 次窃取尝试。因此，一个轮次至少需要 4 个时间步，因为每轮至少包含 \\(3P\\) 次窃取尝试，但不会超过 \\(4P\\) 次。

构成延迟序列的一系列指令是根据通过稍微修改原始 DAG 获得的增强 DAG 来定义的。令 \\(G\\) 表示原始 DAG，即由计算指令作为顶点及其连续（continue）、生成（spawn）和同步（join）边作为边组成的 DAG。增强的 DAG \\(G'\\) 是原始的 DAG \\(G\\) 加上一些新边，如图 3 所示。对于每一组指令 \\(u\\), \\(v\\)，我们展示了 \\((u, v)\\) 是生成边而 \\((u, w)\\) 是连续边，**队列边（deque edges）** \\((w, v)\\) 被放置在 \\(G'\\) 中。这些队列边在图 3 中以虚线表示。在第 2 节中，我们做了一个技术假设，即指令 w 没有**入同步边（incoming join edges）**，因此 \\(G'\\) 是一个 DAG。如果 \\(T_\infty\\) 是 G 中最长路径的长度，则 G' 中最长路径的长度至多为 \\(2T_\infty\\)。值得指出的是，G' 仅仅是一个分析工具。队列边对工作窃取算法的调度和计算的执行没有影响。

队列边是定义关键指令的关键。在执行过程中的任何时间步，如果在 \\(G'\\) 中，指令 \\(v\\) 之前的每一条指令（无论是直接还是间接）都已被执行，我们称尚未执行的指令 \\(v\\) 为**关键指令（critical）**。也就是说，对于从 \\(w\\) 到 \\(v\\) 有一条有向路径的每个指令 \\(w\\)，指令 \\(w\\) 都已被执行。关键指令必须是准备就绪的，因为 G' 包含了 G 的每一条边，但准备就绪的指令可能是关键的，也可能不是。直观地说，引理 4 中就绪双端队列的结构特性保证了，如果线程在就绪队列中处于深处，则这个线程的当前指令不可能是关键的，因为线程当前指令前驱的队列边尚未执行。

我们现在正式定义延迟序列。

**定义 8（Definition 8）**： 延迟序列是满足以下条件的三元组 \\((U, R, \Pi)\\)：

+ \\(U = (u_1, u_2, ..., u_L)\\) 是 \\(G'\\) 中的最大有向路径。具体地，对于 \\(i = 1, 2, ..., L-1\\)，边 \\((u_i, u_{i+1})\\) 属于 \\(G'\\)，指令 \\(u_1\\) 在 \\(G'\\) 中没有入边（指令 \\(u_1\\) 必须是根线程的第一条指令），指令 \\(u_L\\) 在 \\(G'\\) 中没有出边（指令 \\(u_L\\) 必须是根线程的最后一条指令）。
+ R 是一个正整数，表示窃取尝试轮次。
+ \\(\Pi = (\pi_1, \pi_1', \pi_2, \pi_2', ..., \pi_L, \pi_L')\\) 是 R 的一个划分（即 \\(R = \sum_{i=1}^{L} (\pi_i + \pi_i') \\)），其中 \\(\pi_i' \in \\{0, 1\\}\\) 对于每个 \\(i = 1, 2, ..., L\\)。

划分 \\(\Pi\\) 将 R 轮次的序列划分如下。划分的第一部分对应前 \\(\pi_1\\) 轮。第二部分对应在前 \\(\pi_1\\) 轮之后的下一个 \\(\pi_1'\\) 连续轮。第三部分对应在前 \\((\pi_1 + \pi_1')\\) 轮之后的下一个 \\(\pi_2\\) 连续轮，以此类推。我们主要关注对应 \\(\pi_i\\) 的部分，而不是 \\(\pi_i'\\)，因此我们定义第 i **组（group）**轮次为在第 \\(r_i\\) 轮之后开始的 \\(\pi_i\\) 连续轮次，其中 \\(r_i = \sum_{j=1}^{i-1} (\pi_j + \pi_j') \\)。由于 \\(\Pi\\) 是 R 的一个划分并且 \\(\pi_i' \in \\{0, 1\\}\\)， 对于 \\(i = 1, 2, ..., L\\)，我们有（**不等式 5**）：
$$ \sum_{i=1}^{L} \pi_i \geq R - L $$


<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
